{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inference(model, processor, prompts, max_new_tokens=50):\n",
    "    tokenizer = processor.tokenizer\n",
    "    bad_words = [\"<image>\", \"<fake_token_around_image>\"]\n",
    "    if len(bad_words) > 0:\n",
    "        bad_words_ids = tokenizer(bad_words, add_special_tokens=False).input_ids\n",
    "\n",
    "    eos_token = \"</s>\"\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "\n",
    "    inputs = processor(prompts, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(**inputs, eos_token_id=[eos_token_id], bad_words_ids=bad_words_ids, max_new_tokens=max_new_tokens, early_stopping=False)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_probabilities(generated_text):\n",
    "    emotion = extract_second_assistant_emotion(generated_text)\n",
    "    emotions = [\"Amusement\", \"Awe\", \"Contentment\", \"Excitement\", \"Fear\", \"Sadness\", \"Anger\", \"Disgust\"]\n",
    "    probabilities = np.zeros(len(emotions))\n",
    "    if emotion in emotions:\n",
    "        index = emotions.index(emotion)\n",
    "        probabilities[index] = 1.0  \n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        url = 'https://via.placeholder.com/100'\n",
    "        prompts = [\n",
    "    [\n",
    "        \"User: Wonderful detail, the sky contrasts nicely with the rest of the painting. The defining outlines of the mother and child are very effective in evoking emotions. Choose one emotion from: Amusement, Awe, Contentment, Excitement, Fear, Sadness, Anger.\",\n",
    "        url,\n",
    "        \"<end_of_utterance>\",\n",
    "        \"\\nAssistant: Awe.<end_of_utterance>\",\n",
    "        \"\\nUser:\",\n",
    "        url,\n",
    "        f\"{texts} Choose one emotion from: Amusement, Awe, Contentment, Excitement, Fear, Sadness, Anger.\",\n",
    "        \"\\nAssistant:\",\n",
    "    ],\n",
    "]\n",
    "        generated_text = check_inference(model, processor, prompts)\n",
    "\n",
    "        emotion_probabilities = extract_probabilities(generated_text)\n",
    "        results.append(emotion_probabilities)\n",
    "    return np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Amusement\", \"Awe\", \"Contentment\", \"Excitement\", \"Fear\", \"Sadness\", \"Anger\", \"Disgust\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = {'utterance': [\"This abstract shows how small the world is. The landscape looks like a gorgeous winter evening, with grounds covered in snow. I can imagine the sounds of whistling winds and howling wolves.\"]}\n",
    "sample_df = pd.DataFrame(data)\n",
    "\n",
    "text_instance = sample_df.iloc[0]['utterance']\n",
    "\n",
    "probabilities = predict_proba([text_instance])\n",
    "\n",
    "print(\"Predicted probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (155478 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "exp = explainer.explain_instance(text_instance, predict_proba, num_features=6)\n",
    "\n",
    "print(exp.as_list())\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assistant_emotion(text):\n",
    "    # Find all occurrences of \"Assistant: \" in the text\n",
    "    parts = re.split(r'Assistant: ', text)\n",
    "\n",
    "    # If there are at least two occurrences\n",
    "    if len(parts) > 1:\n",
    "        # Extract the part after the second \"Assistant: \"\n",
    "        last_assistant_part = parts[-1]\n",
    "\n",
    "        # Find the first emotion word from the specified list\n",
    "        emotions = ['Amusement', 'Awe', 'Contentment', 'Excitement', 'Fear', 'Sadness', 'Anger', 'Disgust']\n",
    "        for emotion in emotions:\n",
    "            if emotion in last_assistant_part:\n",
    "                return emotion\n",
    "\n",
    "    # Return None if no emotion is found\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
